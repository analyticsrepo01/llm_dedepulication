{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "630518d2-9716-432c-9f9d-77794436e02b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Author : Saurabh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30170f5f-c62e-45de-8cb4-f3a9febf215d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# git@github.com:analyticsrepo01/llm_dedepulication.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47e1ab4-4115-41b4-9e5c-dac113af7c8f",
   "metadata": {},
   "source": [
    "### basic setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e2cc595-bbd1-4b87-a900-c43250f9b6f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "PROJECT_ID = !(gcloud config get-value core/project)\n",
    "PROJECT_ID = PROJECT_ID[0]\n",
    "\n",
    "SVC_ACC = !(gcloud config get-value core/account)\n",
    "SVC_ACC = SVC_ACC[0]\n",
    "\n",
    "PROJECT_NUMBER=str(re.search(r'\\d+', SVC_ACC).group())\n",
    "\n",
    "LOCATION=\"asia-southeast1\"\n",
    "\n",
    "FOLDER_NAME=\".\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0099e80-b347-44c0-870b-39d4ae99ff37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from IPython.display import Markdown, display\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from vertexai.preview.language_models import (ChatModel, InputOutputTextPair,\n",
    "                                              TextEmbeddingModel,\n",
    "                                              TextGenerationModel)\n",
    "from google.cloud import aiplatform_v1beta1, aiplatform\n",
    "from google.protobuf import struct_pb2\n",
    "import numpy as np\n",
    "\n",
    "from tenacity import retry, stop_after_attempt, wait_random_exponential\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2ea7522-f30f-4688-9ff8-e94136582df4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import vertexai\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
    "embedding_model =TextEmbeddingModel.from_pretrained(\"textembedding-gecko@latest\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28762ce-a381-4349-ab43-27d623f8161d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Dedup logic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9820e5a4-c072-45f6-8057-c698de4ecf65",
   "metadata": {},
   "source": [
    "### data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b822283c-dad1-4d61-bf36-be947e887b22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load DataFrames\n",
    "df1 = pd.read_csv('database1.csv')\n",
    "df2 = pd.read_csv('database2.csv')\n",
    "\n",
    "# Standardize Company Names\n",
    "def standardize_name(name):\n",
    "    name = name.lower()  # Lowercase\n",
    "    name = name.replace('.', '').replace(',', '')  # Remove punctuation\n",
    "    name = name.replace('limited', 'ltd')  # Abbreviation\n",
    "    return name.strip()  # Remove extra spaces\n",
    "\n",
    "df1['customer_name'] = df1['customer_name'].astype(str).apply(standardize_name)\n",
    "df2['customer_name'] = df2['customer_name'].astype(str).apply(standardize_name)\n",
    "\n",
    "# Standardize Phone Numbers\n",
    "def standardize_phone(phone):\n",
    "    phone = phone.replace('-', '').replace('(', '').replace(')', '').replace(' ', '')  # Remove formatting\n",
    "    if phone.startswith('+1'):  # Remove +1 from US numbers\n",
    "        phone = phone[2:]\n",
    "    return phone\n",
    "\n",
    "df1['customer_phone_number'] = df1['customer_phone_number'].astype(str).apply(standardize_phone)\n",
    "df2['customer_phone_number'] = df2['customer_phone_number'].astype(str).apply(standardize_phone)\n",
    "\n",
    "# Standardize Addresses (Simplified)\n",
    "def standardize_address(address):\n",
    "    address = address.lower()  # Lowercase\n",
    "    address = address.replace('.', '').replace(',', '')  # Remove some punctuation\n",
    "    address = address.replace('street', 'st').replace('avenue', 'ave')  # Abbreviate\n",
    "    return address.strip()\n",
    "\n",
    "df1['customer_address'] = df1['customer_address'].astype(str).apply(standardize_address)\n",
    "df2['customer_address'] = df2['customer_address'].astype(str).apply(standardize_address)\n",
    "\n",
    "# Standardize Directors (Optional)\n",
    "def standardize_directors(directors):\n",
    "    if pd.isna(directors):  # Handle missing values\n",
    "        return \"\"\n",
    "    directors = directors.lower()\n",
    "    directors = directors.replace(' ', '')  # Remove spaces\n",
    "    return directors.split(',')  # Split into a list\n",
    "\n",
    "df1['customer_directors'] = df1['customer_directors'].astype(str).apply(standardize_directors)\n",
    "df2['customer_directors'] = df2['customer_directors'].astype(str).apply(standardize_directors)\n",
    "\n",
    "\n",
    "# ... (you can apply similar logic to standardize emails and other fields)\n",
    "\n",
    "# Create a concatenated field for similarity search\n",
    "df1['concatenated_field'] = df1['customer_name'] + ' ' + df1['customer_address'] \n",
    "df2['concatenated_field'] = df2['customer_name'] + ' ' + df2['customer_address']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54362f63-f4bc-4866-81f3-0d84640a197f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_name</th>\n",
       "      <th>customer_email</th>\n",
       "      <th>customer_phone_number</th>\n",
       "      <th>customer_directors</th>\n",
       "      <th>customer_address</th>\n",
       "      <th>concatenated_field</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>acme corporation</td>\n",
       "      <td>[email address removed]</td>\n",
       "      <td>5551234567</td>\n",
       "      <td>[johnsmith, janedoe]</td>\n",
       "      <td>123 main st anytown usa</td>\n",
       "      <td>acme corporation 123 main st anytown usa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>globex solutions</td>\n",
       "      <td>[email address removed]</td>\n",
       "      <td>5555558901</td>\n",
       "      <td>[robertjohnson]</td>\n",
       "      <td>456 elm ave cityville</td>\n",
       "      <td>globex solutions 456 elm ave cityville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>innovative tech ltd</td>\n",
       "      <td>[email address removed]</td>\n",
       "      <td>+442079460123</td>\n",
       "      <td>[emilydavis, michaelbrown]</td>\n",
       "      <td>789 oak ln london</td>\n",
       "      <td>innovative tech ltd 789 oak ln london</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the coffee house</td>\n",
       "      <td>[email address removed]</td>\n",
       "      <td>5555552345</td>\n",
       "      <td>[nan]</td>\n",
       "      <td>101 java st coffeeville</td>\n",
       "      <td>the coffee house 101 java st coffeeville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bob's plumbing services</td>\n",
       "      <td>[email address removed]</td>\n",
       "      <td>5559876543</td>\n",
       "      <td>[bobjones]</td>\n",
       "      <td>202 pipe dr plumberton</td>\n",
       "      <td>bob's plumbing services 202 pipe dr plumberton</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             customer_name           customer_email customer_phone_number  \\\n",
       "0         acme corporation  [email address removed]            5551234567   \n",
       "1         globex solutions  [email address removed]            5555558901   \n",
       "2      innovative tech ltd  [email address removed]         +442079460123   \n",
       "3         the coffee house  [email address removed]            5555552345   \n",
       "4  bob's plumbing services  [email address removed]            5559876543   \n",
       "\n",
       "           customer_directors         customer_address  \\\n",
       "0        [johnsmith, janedoe]  123 main st anytown usa   \n",
       "1             [robertjohnson]    456 elm ave cityville   \n",
       "2  [emilydavis, michaelbrown]        789 oak ln london   \n",
       "3                       [nan]  101 java st coffeeville   \n",
       "4                  [bobjones]   202 pipe dr plumberton   \n",
       "\n",
       "                               concatenated_field  \n",
       "0        acme corporation 123 main st anytown usa  \n",
       "1          globex solutions 456 elm ave cityville  \n",
       "2           innovative tech ltd 789 oak ln london  \n",
       "3        the coffee house 101 java st coffeeville  \n",
       "4  bob's plumbing services 202 pipe dr plumberton  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7aa8f9f8-9b8b-4264-b4d0-243f25881911",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/jupyter/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords  \n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Download stopwords if you haven't already\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def tokenize_and_create_keyword_set(text):\n",
    "    \"\"\"\n",
    "    Tokenizes text, removes stopwords, and creates a set of keywords.\n",
    "    \"\"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    tokens = word_tokenize(text)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    keywords = [word for word in tokens if not word in stop_words]\n",
    "    return set(keywords)  # Use a set for efficient comparison later\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "815671ea-94fc-439b-a990-13ceceb2e0af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# ... (other imports for text embedding model, keyword matching)\n",
    "\n",
    "# Generate embeddings\n",
    "embedding_model = TextEmbeddingModel.from_pretrained(\"textembedding-gecko@latest\")\n",
    "df1['embedding'] = df1['concatenated_field'].apply(lambda x: embedding_model.get_embeddings([x])[0].values)\n",
    "df2['embedding'] = df2['concatenated_field'].apply(lambda x: embedding_model.get_embeddings([x])[0].values)\n",
    "\n",
    "# Calculate cosine similarity\n",
    "similarities = cosine_similarity(df1['embedding'].tolist(), df2['embedding'].tolist())\n",
    "\n",
    "# Keyword matching\n",
    "df1['keywords'] = df1['concatenated_field'].apply(tokenize_and_create_keyword_set)\n",
    "df2['keywords'] = df2['concatenated_field'].apply(tokenize_and_create_keyword_set)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e81a37-bfe7-4ae9-a778-30e983b4f63c",
   "metadata": {},
   "source": [
    "### calculate keyword overlap scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e6fd2fb-ab6d-4da8-af84-e2b0e7a4cf05",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             customer_name  intersection_score  jaccard_score\n",
      "0         acme corporation                   6       0.750000\n",
      "1         globex solutions                   6       0.857143\n",
      "2      innovative tech ltd                   4       0.444444\n",
      "3         the coffee house                   5       0.714286\n",
      "4  bob's plumbing services                   4       0.400000\n",
      "          customer_name  intersection_score  jaccard_score\n",
      "0             acme corp                   6       0.750000\n",
      "1  globex solutions llc                   6       0.857143\n",
      "2        innovatech ltd                   4       0.444444\n",
      "3          coffee house                   5       0.714286\n",
      "4    bob jones plumbing                   4       0.400000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_42068/2885201816.py:24: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.75' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df1.at[i, 'jaccard_score'] = max(df1.at[i, 'jaccard_score'], jaccard)\n",
      "/var/tmp/ipykernel_42068/2885201816.py:26: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.75' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df2.at[j, 'jaccard_score'] = max(df2.at[j, 'jaccard_score'], jaccard)\n"
     ]
    }
   ],
   "source": [
    "# ... (previous code for loading, cleaning, and keyword set creation)\n",
    "\n",
    "# Calculate Keyword Overlap Scores\n",
    "def calculate_keyword_overlap(keywords1, keywords2):\n",
    "    \"\"\"\n",
    "    Calculates set intersection and Jaccard similarity for two keyword sets.\n",
    "    \"\"\"\n",
    "    intersection = len(keywords1.intersection(keywords2))\n",
    "    union = len(keywords1.union(keywords2))\n",
    "    jaccard_sim = intersection / union if union > 0 else 0  # Avoid division by zero\n",
    "    return intersection, jaccard_sim\n",
    "\n",
    "# Create Empty Columns for Scores\n",
    "df1['intersection_score'] = 0\n",
    "df1['jaccard_score'] = 0\n",
    "df2['intersection_score'] = 0\n",
    "df2['jaccard_score'] = 0\n",
    "\n",
    "# Calculate Scores for Each Pair\n",
    "for i, row1 in df1.iterrows():\n",
    "    for j, row2 in df2.iterrows():\n",
    "        intersection, jaccard = calculate_keyword_overlap(row1['keywords'], row2['keywords'])\n",
    "        df1.at[i, 'intersection_score'] = max(df1.at[i, 'intersection_score'], intersection)\n",
    "        df1.at[i, 'jaccard_score'] = max(df1.at[i, 'jaccard_score'], jaccard)\n",
    "        df2.at[j, 'intersection_score'] = max(df2.at[j, 'intersection_score'], intersection)\n",
    "        df2.at[j, 'jaccard_score'] = max(df2.at[j, 'jaccard_score'], jaccard)\n",
    "\n",
    "# Print the DataFrames with Scores\n",
    "print(df1[['customer_name', 'intersection_score', 'jaccard_score']])\n",
    "print(df2[['customer_name', 'intersection_score', 'jaccard_score']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e083ef45-81f2-4f94-920f-be664b201117",
   "metadata": {},
   "source": [
    "### Combine scores and identify duplicates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b7816b98-478e-4b1d-ade4-46074c3c5429",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    customer_name_1       customer_name_2  similarity_score  jaccard_score\n",
      "0  acme corporation             acme corp          0.994756       0.750000\n",
      "1  globex solutions  globex solutions llc          0.991921       0.857143\n",
      "2  the coffee house          coffee house          0.925139       0.714286\n"
     ]
    }
   ],
   "source": [
    "# ... (previous code for loading, cleaning, embedding generation, and keyword overlap calculation)\n",
    "\n",
    "# Combine Scores and Identify Duplicates\n",
    "THRESHOLD_SIMILARITY = 0.85   # Adjust based on your data\n",
    "THRESHOLD_JACCARD = 0.5       # Adjust based on your data\n",
    "\n",
    "potential_duplicates = []\n",
    "\n",
    "for i, row1 in df1.iterrows():\n",
    "    for j, row2 in df2.iterrows():\n",
    "        if similarities[i][j] >= THRESHOLD_SIMILARITY and row1['jaccard_score'] >= THRESHOLD_JACCARD:\n",
    "            potential_duplicates.append((row1['customer_name'], row2['customer_name'], similarities[i][j], row1['jaccard_score']))\n",
    "\n",
    "# Create a DataFrame of Potential Duplicates\n",
    "potential_duplicates_df = pd.DataFrame(potential_duplicates, columns=['customer_name_1', 'customer_name_2', 'similarity_score', 'jaccard_score'])\n",
    "\n",
    "# Print Potential Duplicates\n",
    "print(potential_duplicates_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7d4a17-909c-468b-ae8e-7a3284fdb7b5",
   "metadata": {},
   "source": [
    "### Hybrid Approach for Duplicate Identification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dfd90862-6678-4389-abb2-1c269cdac7a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            customer_name_1       customer_name_2  similarity_score  \\\n",
      "0          acme corporation             acme corp          0.994756   \n",
      "1          acme corporation  globex solutions llc          0.651831   \n",
      "2          acme corporation        innovatech ltd          0.618742   \n",
      "3          acme corporation          coffee house          0.673708   \n",
      "4          acme corporation    bob jones plumbing          0.608970   \n",
      "5          globex solutions             acme corp          0.632943   \n",
      "6          globex solutions  globex solutions llc          0.991921   \n",
      "7          globex solutions        innovatech ltd          0.639730   \n",
      "8          globex solutions          coffee house          0.600899   \n",
      "9          globex solutions    bob jones plumbing          0.630439   \n",
      "10      innovative tech ltd        innovatech ltd          0.926730   \n",
      "11         the coffee house             acme corp          0.689812   \n",
      "12         the coffee house  globex solutions llc          0.661415   \n",
      "13         the coffee house          coffee house          0.925139   \n",
      "14         the coffee house    bob jones plumbing          0.642430   \n",
      "15  bob's plumbing services    bob jones plumbing          0.942742   \n",
      "\n",
      "    jaccard_score  \n",
      "0        0.750000  \n",
      "1        0.750000  \n",
      "2        0.750000  \n",
      "3        0.750000  \n",
      "4        0.750000  \n",
      "5        0.857143  \n",
      "6        0.857143  \n",
      "7        0.857143  \n",
      "8        0.857143  \n",
      "9        0.857143  \n",
      "10       0.444444  \n",
      "11       0.714286  \n",
      "12       0.714286  \n",
      "13       0.714286  \n",
      "14       0.714286  \n",
      "15       0.400000  \n"
     ]
    }
   ],
   "source": [
    "# ... (previous code for loading, cleaning, embedding generation, and keyword overlap calculation)\n",
    "\n",
    "# Hybrid Approach for Duplicate Identification\n",
    "def is_potential_duplicate(sim_score, jaccard_score):\n",
    "    \"\"\"\n",
    "    Determines if a pair of records is a potential duplicate based on a hybrid approach.\n",
    "    \"\"\"\n",
    "    # Weighted average with emphasis on similarity\n",
    "    combined_score = 0.7 * sim_score + 0.3 * jaccard_score\n",
    "    \n",
    "    # Additional rules for handling specific cases (optional)\n",
    "    if sim_score > 0.9 and jaccard_score > 0.2:  # High similarity, moderate keywords\n",
    "        return True\n",
    "    elif sim_score > 0.8 and jaccard_score > 0.4:  # Moderate similarity, good keywords\n",
    "        return True\n",
    "    elif combined_score > 0.65:                     # Overall decent score\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# Identify Potential Duplicates\n",
    "potential_duplicates = []\n",
    "for i, row1 in df1.iterrows():\n",
    "    for j, row2 in df2.iterrows():\n",
    "        if is_potential_duplicate(similarities[i][j], row1['jaccard_score']):\n",
    "            potential_duplicates.append((row1['customer_name'], row2['customer_name'], similarities[i][j], row1['jaccard_score']))\n",
    "\n",
    "# Create a DataFrame of Potential Duplicates\n",
    "potential_duplicates_df = pd.DataFrame(potential_duplicates, columns=['customer_name_1', 'customer_name_2', 'similarity_score', 'jaccard_score'])\n",
    "\n",
    "# Print Potential Duplicates\n",
    "print(potential_duplicates_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7f14ede5-43c8-43b8-9f2e-daf7362da7af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   customer_name customer_email customer_phone_number customer_directors  \\\n",
      "0            NaN            NaN                   NaN                NaN   \n",
      "1            NaN            NaN                   NaN                NaN   \n",
      "2            NaN            NaN                   NaN                NaN   \n",
      "3            NaN            NaN                   NaN                NaN   \n",
      "4            NaN            NaN                   NaN                NaN   \n",
      "5            NaN            NaN                   NaN                NaN   \n",
      "6            NaN            NaN                   NaN                NaN   \n",
      "7            NaN            NaN                   NaN                NaN   \n",
      "8            NaN            NaN                   NaN                NaN   \n",
      "9            NaN            NaN                   NaN                NaN   \n",
      "10           NaN            NaN                   NaN                NaN   \n",
      "11           NaN            NaN                   NaN                NaN   \n",
      "12           NaN            NaN                   NaN                NaN   \n",
      "13           NaN            NaN                   NaN                NaN   \n",
      "14           NaN            NaN                   NaN                NaN   \n",
      "15           NaN            NaN                   NaN                NaN   \n",
      "\n",
      "   customer_address concatenated_field          customer_name_1  \\\n",
      "0               NaN                NaN         acme corporation   \n",
      "1               NaN                NaN         acme corporation   \n",
      "2               NaN                NaN         acme corporation   \n",
      "3               NaN                NaN         acme corporation   \n",
      "4               NaN                NaN         acme corporation   \n",
      "5               NaN                NaN         globex solutions   \n",
      "6               NaN                NaN         globex solutions   \n",
      "7               NaN                NaN         globex solutions   \n",
      "8               NaN                NaN         globex solutions   \n",
      "9               NaN                NaN         globex solutions   \n",
      "10              NaN                NaN      innovative tech ltd   \n",
      "11              NaN                NaN         the coffee house   \n",
      "12              NaN                NaN         the coffee house   \n",
      "13              NaN                NaN         the coffee house   \n",
      "14              NaN                NaN         the coffee house   \n",
      "15              NaN                NaN  bob's plumbing services   \n",
      "\n",
      "         customer_name_2  similarity_score is_potential_duplicate  \n",
      "0              acme corp          0.994756                   True  \n",
      "1   globex solutions llc          0.651831                   True  \n",
      "2         innovatech ltd          0.618742                   True  \n",
      "3           coffee house          0.673708                   True  \n",
      "4     bob jones plumbing          0.608970                   True  \n",
      "5              acme corp          0.632943                   True  \n",
      "6   globex solutions llc          0.991921                   True  \n",
      "7         innovatech ltd          0.639730                   True  \n",
      "8           coffee house          0.600899                   True  \n",
      "9     bob jones plumbing          0.630439                   True  \n",
      "10        innovatech ltd          0.926730                   True  \n",
      "11             acme corp          0.689812                   True  \n",
      "12  globex solutions llc          0.661415                   True  \n",
      "13          coffee house          0.925139                   True  \n",
      "14    bob jones plumbing          0.642430                   True  \n",
      "15    bob jones plumbing          0.942742                   True  \n"
     ]
    }
   ],
   "source": [
    "# ... (previous code for loading, cleaning, embedding generation, keyword overlap calculation, and duplicate identification)\n",
    "\n",
    "# Create Sets of Duplicate IDs\n",
    "duplicate_ids_df1 = set(potential_duplicates_df['customer_name_1'])\n",
    "duplicate_ids_df2 = set(potential_duplicates_df['customer_name_2'])\n",
    "\n",
    "# Combine Non-Duplicate Entries\n",
    "non_duplicate_df1 = df1[~df1['customer_name'].isin(duplicate_ids_df1)].copy()\n",
    "non_duplicate_df2 = df2[~df2['customer_name'].isin(duplicate_ids_df2)].copy()\n",
    "combined_non_duplicates_df = pd.concat([non_duplicate_df1, non_duplicate_df2])\n",
    "\n",
    "\n",
    "# Add a Flag for Potential Duplicates\n",
    "potential_duplicates_df[\"is_potential_duplicate\"] = True\n",
    "\n",
    "# Combine with Potential Duplicates\n",
    "final_df = pd.concat([combined_non_duplicates_df, potential_duplicates_df])\n",
    "\n",
    "# Remove Unnecessary Columns (Optional)\n",
    "final_df = final_df.drop(columns=['embedding', 'keywords', 'intersection_score', 'jaccard_score'])\n",
    "\n",
    "# Print Final DataFrame\n",
    "print(final_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9547eb02-b1b3-4637-bd5c-1db339a6ea88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "workbench-notebooks.m113",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m113"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
